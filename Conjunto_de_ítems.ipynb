{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "M-pfZAkRg7gW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La minería de datos frecuentes, también conocida como minería de conjuntos de ítems frecuentes, es un aspecto crucial en el análisis de datos, especialmente en el contexto de reglas de asociación y patrones de compra. Esta técnica se centra en identificar conjuntos de ítems que aparecen juntos con frecuencia en un conjunto de datos. A continuación, se detallan algunos conceptos clave y algoritmos relacionados:\n",
        "\n",
        "### Conceptos\n",
        "1. **Conjuntos de Ítems**: grupos de elementos que aparecen juntos en una transacción o evento.\n",
        "2. **Soporte**: la frecuencia relativa de un conjunto de ítems en el conjunto de datos. Es una medida de cuán a menudo aparece un conjunto de ítems en el conjunto de datos.\n",
        "3. **Confianza**: una medida de cuán a menudo los ítems en un conjunto de ítems ocurren juntos, dado que otros ítems están presentes.\n",
        "4. **Reglas de Asociación**: Implicaciones en forma de A => B, donde A y B son conjuntos de ítems. Indica que cuando A ocurre, B también suele ocurrir.\n",
        "\n",
        "### Principales algoritmos\n",
        "1. **Apriori**: utiliza un enfoque iterativo basado en el nivel para construir conjuntos de ítems frecuentes. Comienza con conjuntos de un solo ítem y aumenta su tamaño en cada iteración, utilizando la propiedad de que un subconjunto de un conjunto de ítems frecuente también debe ser frecuente.\n",
        "\n",
        "2. **FP-Growth (Frequent Pattern Growth)**: construye un árbol especial (FP-tree) para comprimir el conjunto de datos y luego extrae los conjuntos de ítems frecuentes directamente de esta estructura. Es eficiente en términos de velocidad y uso de memoria, especialmente en grandes bases de datos.\n",
        "\n",
        "3. **Eclat (Equivalence Class Clustering and Bottom-Up Lattice Traversal)**: Trabaja con una representación vertical del conjunto de datos, realizando intersecciones de conjuntos para encontrar ítems frecuentes. Es particularmente eficaz en conjuntos de datos con una estructura densa.\n",
        "\n",
        "### Aplicaciones\n",
        "- **Análisis de mercado y cestas de compra**: identificar productos que se compran frecuentemente juntos.\n",
        "- **Análisis de fraudes**: detectar patrones de comportamiento sospechoso.\n",
        "- **Bioinformática**: encontrar patrones comunes en secuencias de ADN o proteínas.\n",
        "\n"
      ],
      "metadata": {
        "id": "I-bdPCt5erF-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IA3toFPHeoGe"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo del algoritmo Apriori"
      ],
      "metadata": {
        "id": "Fbzm3jIuo9s_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import apriori\n",
        "\n",
        "# Conjunto de datos de ejemplo\n",
        "dataset = [['Pan', 'Leche'],\n",
        "           ['Pan', 'Pañales', 'Cerveza', 'Huevos'],\n",
        "           ['Leche', 'Pañales', 'Cerveza', 'Pepsi'],\n",
        "           ['Pan', 'Leche', 'Pañales', 'Cerveza'],\n",
        "           ['Pan', 'Leche', 'Coca Cola']]\n",
        "\n",
        "# Transformar los datos a formato de matriz binaria\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(dataset).transform(dataset)\n",
        "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "\n",
        "# Aplicar el algoritmo Apriori\n",
        "frequent_itemsets = apriori(df, min_support=0.5, use_colnames=True)\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(frequent_itemsets)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aR1I6Y8efP2H",
        "outputId": "8e76f51f-3b8e-45b0-fa91-47fc62fc78d9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   support            itemsets\n",
            "0      0.6           (Cerveza)\n",
            "1      0.8             (Leche)\n",
            "2      0.8               (Pan)\n",
            "3      0.6           (Pañales)\n",
            "4      0.6  (Cerveza, Pañales)\n",
            "5      0.6        (Pan, Leche)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **Cerveza (support = 0.6)**: el ítem 'Cerveza' aparece en el 60% de todas las transacciones.\n",
        "\n",
        "2. **Leche (support = 0.8)**: el ítem 'Leche' se encuentra en el 80% de las transacciones.\n",
        "\n",
        "3. **Pan (support = 0.8)**: el ítem 'Pan' también aparece en el 80% de las transacciones.\n",
        "\n",
        "4. **Pañales (support = 0.6)**: 'Pañales' se encuentra en el 60% de las transacciones.\n",
        "\n",
        "5. **Pañales, Cerveza (support = 0.6)**: el conjunto de ítems 'Pañales' y 'Cerveza' aparece juntos en el 60% de las transacciones. Esto sugiere una fuerte relación entre la compra de 'Pañales' y 'Cerveza'.\n",
        "\n",
        "6. **Pan, Leche (support = 0.6)**: el conjunto de 'Pan' y 'Leche' se encuentra en el 60% de las transacciones, indicando que estos dos ítems a menudo se compran juntos.\n",
        "\n",
        "La interpretación de estos resultados puede ser útil para comprender los patrones de compra de los clientes. Por ejemplo, los ítems con mayor soporte individual (como 'Leche' y 'Pan' en este caso) suelen ser productos básicos o esenciales. Por otro lado, conjuntos de ítems con alto soporte, como 'Pañales y Cerveza' o 'Pan y Leche', pueden indicar que estos productos se compran juntos con frecuencia, lo que podría ser relevante para estrategias de marketing, como promociones cruzadas o la colocación de productos en una tienda."
      ],
      "metadata": {
        "id": "KJIxSgVFfzxh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo del algoritmo FP-Growt"
      ],
      "metadata": {
        "id": "_ehIbHWZgXqz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
        "\n",
        "# Supongamos que 'data' es tu DataFrame cargado con transacciones\n",
        "# Deberás ajustar esto para que coincida con la estructura de tus datos reales\n",
        "data = [['Milk', 'Bread', 'Wheat'],\n",
        "        ['Milk', 'Cheese'],\n",
        "        ['Cheese', 'Boots'],\n",
        "        ['Cheese', 'Milk', 'Bread', 'Wheat'],\n",
        "        ['Milk', 'Bread', 'Wheat']]\n",
        "\n",
        "# Transformar los datos a formato de matriz binaria\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(data).transform(data)\n",
        "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "\n",
        "# Aplicar el algoritmo FP-Growth\n",
        "frequent_itemsets = fpgrowth(df, min_support=0.3, use_colnames=True)\n",
        "\n",
        "# Generar reglas de asociación\n",
        "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.7)\n",
        "\n",
        "# Mostrar los resultados\n",
        "print(frequent_itemsets)\n",
        "print(rules)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVeBO3VsgTll",
        "outputId": "db3d3f9d-78ab-4cdd-e0cf-8fe92f3ce6ff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   support              itemsets\n",
            "0      0.8                (Milk)\n",
            "1      0.6               (Wheat)\n",
            "2      0.6               (Bread)\n",
            "3      0.6              (Cheese)\n",
            "4      0.6         (Milk, Wheat)\n",
            "5      0.6        (Wheat, Bread)\n",
            "6      0.6         (Milk, Bread)\n",
            "7      0.6  (Milk, Bread, Wheat)\n",
            "8      0.4        (Cheese, Milk)\n",
            "       antecedents     consequents  antecedent support  consequent support  \\\n",
            "0           (Milk)         (Wheat)                 0.8                 0.6   \n",
            "1          (Wheat)          (Milk)                 0.6                 0.8   \n",
            "2          (Wheat)         (Bread)                 0.6                 0.6   \n",
            "3          (Bread)         (Wheat)                 0.6                 0.6   \n",
            "4           (Milk)         (Bread)                 0.8                 0.6   \n",
            "5          (Bread)          (Milk)                 0.6                 0.8   \n",
            "6    (Milk, Bread)         (Wheat)                 0.6                 0.6   \n",
            "7    (Milk, Wheat)         (Bread)                 0.6                 0.6   \n",
            "8   (Wheat, Bread)          (Milk)                 0.6                 0.8   \n",
            "9           (Milk)  (Wheat, Bread)                 0.8                 0.6   \n",
            "10         (Bread)   (Milk, Wheat)                 0.6                 0.6   \n",
            "11         (Wheat)   (Milk, Bread)                 0.6                 0.6   \n",
            "\n",
            "    support  confidence      lift  leverage  conviction  zhangs_metric  \n",
            "0       0.6        0.75  1.250000      0.12         1.6            1.0  \n",
            "1       0.6        1.00  1.250000      0.12         inf            0.5  \n",
            "2       0.6        1.00  1.666667      0.24         inf            1.0  \n",
            "3       0.6        1.00  1.666667      0.24         inf            1.0  \n",
            "4       0.6        0.75  1.250000      0.12         1.6            1.0  \n",
            "5       0.6        1.00  1.250000      0.12         inf            0.5  \n",
            "6       0.6        1.00  1.666667      0.24         inf            1.0  \n",
            "7       0.6        1.00  1.666667      0.24         inf            1.0  \n",
            "8       0.6        1.00  1.250000      0.12         inf            0.5  \n",
            "9       0.6        0.75  1.250000      0.12         1.6            1.0  \n",
            "10      0.6        1.00  1.666667      0.24         inf            1.0  \n",
            "11      0.6        1.00  1.666667      0.24         inf            1.0  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyECLAT\n",
        "from pyECLAT import Example1, Example2\n",
        "ex1 = Example1().get()\n",
        "ex2 = Example2().get()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3-cRXbrs2sq",
        "outputId": "2056bc33-f7fa-4066-ccf8-42807f808b4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyECLAT in /usr/local/lib/python3.10/dist-packages (1.0.2)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /usr/local/lib/python3.10/dist-packages (from pyECLAT) (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.17.4 in /usr/local/lib/python3.10/dist-packages (from pyECLAT) (1.23.5)\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.10/dist-packages (from pyECLAT) (4.66.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->pyECLAT) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.3->pyECLAT) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.25.3->pyECLAT) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyECLAT import ECLAT\n",
        "eclat_instance = ECLAT(data=ex1, verbose=True)\n",
        "eclat_instance.df_bin   #generate a binary dataframe, that can be used for other analyzes.\n",
        "eclat_instance.uniq_    #a list with all the names of the different items\n",
        "get_ECLAT_indexes, get_ECLAT_supports = eclat_instance.fit(min_support=0.08,\n",
        "                                                           min_combination=1,\n",
        "                                                           max_combination=3,\n",
        "                                                           separator=' & ',\n",
        "                                                           verbose=True)\n",
        "get_ECLAT_indexes\n",
        "get_ECLAT_supports"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eps2YZSJuiqa",
        "outputId": "2df8a38d-b6ef-47df-a311-ca223edd0574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n",
            "100%|██████████| 7/7 [00:00<00:00, 674.79it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 42612.67it/s]\n",
            "100%|██████████| 7/7 [00:00<00:00, 1377.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combination 1 by 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "7it [00:00, 156.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combination 2 by 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:00, 213.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combination 3 by 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "35it [00:00, 236.38it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'coffe': 0.3,\n",
              " 'beer': 0.2,\n",
              " 'rice': 0.2,\n",
              " 'bread': 0.5,\n",
              " 'milk': 0.2,\n",
              " 'bean': 0.2,\n",
              " 'butter': 0.5,\n",
              " 'coffe & bread': 0.3,\n",
              " 'coffe & milk': 0.1,\n",
              " 'coffe & butter': 0.3,\n",
              " 'beer & bread': 0.1,\n",
              " 'beer & milk': 0.1,\n",
              " 'beer & butter': 0.1,\n",
              " 'rice & bean': 0.1,\n",
              " 'bread & milk': 0.2,\n",
              " 'bread & butter': 0.4,\n",
              " 'milk & butter': 0.2,\n",
              " 'coffe & bread & milk': 0.1,\n",
              " 'coffe & bread & butter': 0.3,\n",
              " 'coffe & milk & butter': 0.1,\n",
              " 'beer & bread & milk': 0.1,\n",
              " 'beer & bread & butter': 0.1,\n",
              " 'beer & milk & butter': 0.1,\n",
              " 'bread & milk & butter': 0.2}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taller\n",
        "\n",
        "https://www.kaggle.com/datasets/newshuntkannada/dataset-for-apriori-and-fp-growth-algorithm\n",
        "\n",
        "Acceda a la base de datos del enlace y aplique los tres algoritmos revisados. Genere un breve informe con los resultados."
      ],
      "metadata": {
        "id": "UmLLqJrepWEF"
      }
    }
  ]
}